{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "from imblearn.under_sampling import  RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler\n",
    "from scipy.stats import norm\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Class_imbalance = pd.concat([df.Class.value_counts().to_frame(),df.Class.value_counts(normalize=True).to_frame()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Class_imbalance.columns = ['no of Transactions','Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Class_imbalance.index = [\"no fraud\",\"fraud\"]\n",
    "Class_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fg = go.Figure(data=[go.Pie(labels=df['Class'],hole=0.5)])\n",
    "fg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Scaler_def(_Scaler,df_copy):\n",
    "\n",
    "    df_amount = df_copy['Amount'].values.reshape(-1,1)\n",
    "    df_Time = df_copy.Time.values.reshape(-1,1)\n",
    "    y = df.Class\n",
    "\n",
    "    df_copy['Scaled_Amount'] = _Scaler.fit_transform(df_amount)\n",
    "    df_copy['Scaled_Time'] = _Scaler.fit_transform(df_Time)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "    amount_val = df_copy['Scaled_Amount'].values\n",
    "    time_val = df_copy['Scaled_Time'].values\n",
    "\n",
    "    sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "    ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "    ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "    sns.distplot(time_val, ax=ax[1], color='b')\n",
    "    ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "    ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "Scaler_def(robust_scaler,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MinMax_Scaler = MinMaxScaler()\n",
    "Scaler_def(MinMax_Scaler,df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Standard_Scaler = StandardScaler()\n",
    "Scaler_def(Standard_Scaler,df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df.drop(['Time','Amount'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.insert(0,'scaled_Time',df['Scaled_Time'])\n",
    "df.insert(1,'scaled_Amount',df['Scaled_Amount'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['Scaled_Amount','Scaled_Time'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(16,4))\n",
    "\n",
    "sns.distplot(df[(df['Class'] == 1)]['scaled_Time'], bins=100, color='red', ax=axs[0])\n",
    "axs[0].set_title(\"Distribution of Fraud Transactions\")\n",
    "\n",
    "sns.distplot(df[(df['Class'] == 0)]['scaled_Time'], bins=100, color='green', ax=axs[1])\n",
    "axs[1].set_title(\"Distribution of Genuine Transactions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(x='Class', y='scaled_Time',data = df)\n",
    "\n",
    "# Change the appearance of that box\n",
    "ax.artists[0].set_facecolor('#90EE90')\n",
    "ax.artists[1].set_facecolor('#FA8072')\n",
    "\n",
    "plt.title('Time Distribution for Fraud and Genuine transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8 , 6))\n",
    "ax = sns.boxplot(x='Class', y='scaled_Amount', data=df)\n",
    "\n",
    "# Change the appearance of that box\n",
    "ax.artists[0].set_facecolor('#90EE90')\n",
    "ax.artists[1].set_facecolor('#FA8072')\n",
    "\n",
    "plt.title('Time Distribution for Fraud and Genuine transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(normal_distributed_df,x='scaled_Time',y='scaled_Amount',color='Class' ,marginal_x=\"histogram\", marginal_y=\"violin\",template=\"simple_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(normal_distributed_df,x='scaled_Time',y='scaled_Amount',facet_col='Class' ,marginal_x=\"histogram\", marginal_y=\"rug\",trendline='ols',template='ggplot2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Pearson Correlation Matrix')\n",
    "sns.heatmap(df[['scaled_Time', 'scaled_Amount','Class']].corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"summer\",\n",
    "            linecolor='w',annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('{} and {}'.format(np.max(df.V1),np.min(df.V1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import  math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Converting time from second to hour\n",
    "df['Time'] = df['Time'].apply(lambda sec : (sec/3600))\n",
    "# Calculating hour of the day\n",
    "df['hour'] = df['Time']%24   # 2 days of data\n",
    "df['hour'] = df['hour'].apply(lambda x : math.floor(x))\n",
    "# Calculating First and Second day\n",
    "df['day'] = df['Time']/24   # 2 days of data\n",
    "df['day'] = df['day'].apply(lambda x : 1 if(x==0) else math.ceil(x))\n",
    "df[['Time','hour','day','Class','Amount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.day.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(normal_distributed_df,x='hour',y='scaled_Amount',color='Class' ,marginal_x=\"histogram\", marginal_y=\"violin\",template=\"simple_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(normal_distributed_df,x='hour',y='scaled_Amount',facet_col='Class' ,marginal_x=\"histogram\", marginal_y=\"rug\",trendline='ols',template='ggplot2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df,x='hour',y='scaled_Amount',facet_col='Class' ,marginal_x=\"box\", marginal_y=\"rug\",trendline='ols',template='ggplot2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "CreditCardFraudDataCleaned = df\n",
    "\n",
    "# Saving the Python objects as serialized files can be done using pickle library\n",
    "# Here let us save the Final Data set after all the transformations as a file\n",
    "with open('CreditCardFraudDataCleaned.pkl', 'wb') as fileWriteStream:\n",
    "    pickle.dump(CreditCardFraudDataCleaned, fileWriteStream)\n",
    "    # Don't forget to close the filestream!\n",
    "    fileWriteStream.close()\n",
    "\n",
    "print('pickle file is saved at Location:',os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "with open('CreditCardFraudDataCleaned.pkl', 'rb') as fileReadStream:\n",
    "    CreditCardFraudDataFromPickle = pickle.load(fileReadStream)\n",
    "    # Don't forget to close the filestream!\n",
    "    fileReadStream.close()\n",
    "\n",
    "# Checking the data read from pickle file. It is exactly same as the DiamondPricesData\n",
    "df_backup = CreditCardFraudDataFromPickle\n",
    "df_backup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(30,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df,x='Amount',y='scaled_Time',color='Class',nbins=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['hour','Amount','Class','day'],axis=1)\n",
    "y = df.Class\n",
    "\n",
    "print(X.columns)\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=101)\n",
    "\n",
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(\"X_train - \",X_train.shape)\n",
    "print(\"y_train - \",y_train.shape)\n",
    "print(\"X_test - \",X_test.shape)\n",
    "print(\"y_test - \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Importing Classifier Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.Series(y_pred).value_counts(normalize=True),pd.Series(y_pred).value_counts(normalize=False),pd.Series(y_pred).value_counts(normalize=True),pd.Series(y_pred).value_counts(normalize=False)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[[85296 ,   10]\n",
    " [   55  ,  82]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "plt.Figure(figsize=(5,5))\n",
    "\n",
    "fig = ff.create_annotated_heatmap(confusion_matrix(y_test,y_pred),colorscale='Viridis',annotation_text=[[85296 ,   10],[55  ,82]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['No Fraud', 'Fraud']\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plot_confusion_matrix(conf_matrix, labels, title=\"Random UnderSample \\n Confusion Matrix\", cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Heatmap for Confusion Matrix\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    p = sns.heatmap(pd.DataFrame(conf_matrix), annot=True, annot_kws={\"size\": 25}, cmap=\"winter\" ,fmt='g')\n",
    "\n",
    "    plt.title('Confusion matrix', y=1.1, fontsize = 22)\n",
    "    plt.ylabel('Actual',fontsize = 18)\n",
    "    plt.xlabel('Predicted',fontsize = 18)\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Genuine', 'Fraud']);\n",
    "    ax.yaxis.set_ticklabels(['Genuine', 'Fraud']);\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot ROC Curve\n",
    "from sklearn import metrics\n",
    "def plot_auc(y_test, y_pred):\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(\"AUC - \",auc,\"\\n\")\n",
    "\n",
    "    plt.plot(fpr,tpr,linewidth=2, label=\"data 1, auc=\"+str(auc))\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "    plt.plot([0,1], [0,1], 'k--' )\n",
    "\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for Predicting a credit card fraud detection')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_auc(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Under Sampling Method with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter # counter takes values returns value_counts dictionary\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Undersampling only on train\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_rus = LogisticRegression()\n",
    "log_reg_rus.fit(X_train_rus,y_train_rus)\n",
    "\n",
    "y_pred_rus = log_reg_rus.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(y_test,y_pred_rus):\n",
    "\n",
    "    print('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_pred_rus , y_test)))\n",
    "    print('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_test , y_pred_rus)))\n",
    "    print('Precision : {0:0.5f}'.format(metrics.precision_score(y_test , y_pred_rus)))\n",
    "    print('Recall : {0:0.5f}'.format(metrics.recall_score(y_test , y_pred_rus)))\n",
    "    print('F1 : {0:0.5f}'.format(metrics.f1_score(y_test , y_pred_rus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(y_test,y_pred_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_auc(y_test,y_pred_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Oversampling Method with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_ros = LogisticRegression()\n",
    "log_reg_ros.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "y_pred_ros = log_reg_ros.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(y_test,y_pred_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_auc(y_test,y_pred_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## using SMOTE method with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_smote = LogisticRegression(max_iter=1000)\n",
    "log_reg_smote.fit(X_train_smote,y_train_smote)\n",
    "\n",
    "y_pred_smote = log_reg_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(y_test,y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_auc(y_test,y_pred_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using ADASYN with Logiestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_adasyn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_adasyn = LogisticRegression(max_iter=1000)\n",
    "log_reg_adasyn.fit(X_train_adasyn,y_train_adasyn)\n",
    "\n",
    "y_pred_adasyn = log_reg_adasyn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(y_test,y_pred_adasyn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_auc(y_test,y_pred_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
